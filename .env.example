# Application Port
PORT=6340

# Qdrant Configuration
# URL for your running Qdrant instance
QDRANT_URL=http://localhost:6333
# API Key for your Qdrant instance
QDRANT_API_KEY=super-secret-dev-key

# --- Embeddings Provider Configuration ---
# This specifies that we're using the LLM toolkit as the provider for embeddings
EMBEDDING_PROVIDER=ubc-genai-toolkit-llm

# --- LLM Provider Settings (for Embeddings) ---
# We are using Ollama to serve the embedding model
LLM_PROVIDER=ollama
# The API key is not required for a local Ollama instance, but the field is expected
LLM_API_KEY=nokey
# The default local endpoint for the Ollama server
LLM_ENDPOINT=http://localhost:11434
# The specific model to use for generating embeddings
LLM_EMBEDDING_MODEL=nomic-embed-text
# A default model name is required by the LLM module for initialization.
LLM_DEFAULT_MODEL=llama3.1